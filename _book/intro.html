<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Introduction | An Introduction to Bayesian Statistics</title>
  <meta name="description" content="This is a set of lecture notes." />
  <meta name="generator" content="bookdown 0.21.6 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Introduction | An Introduction to Bayesian Statistics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a set of lecture notes." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Introduction | An Introduction to Bayesian Statistics" />
  
  <meta name="twitter:description" content="This is a set of lecture notes." />
  

<meta name="author" content="Manuele Leonelli" />


<meta name="date" content="2021-02-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="bin.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">An Introduction to Bayesian Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#a-more-technical-discussion"><i class="fa fa-check"></i><b>1.1</b> A more technical discussion</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#a-first-example"><i class="fa fa-check"></i><b>1.2</b> A first example</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#why-bayesian-statistics"><i class="fa fa-check"></i><b>1.3</b> Why Bayesian statistics</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#a-bit-of-history"><i class="fa fa-check"></i><b>1.4</b> A bit of history</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#interpretations-of-probability"><i class="fa fa-check"></i><b>1.5</b> Interpretations of probability</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#a-review-of-probability"><i class="fa fa-check"></i><b>1.6</b> A review of probability</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="intro.html"><a href="intro.html#random-variables"><i class="fa fa-check"></i><b>1.6.1</b> Random variables</a></li>
<li class="chapter" data-level="1.6.2" data-path="intro.html"><a href="intro.html#joint-distributions"><i class="fa fa-check"></i><b>1.6.2</b> Joint distributions</a></li>
<li class="chapter" data-level="1.6.3" data-path="intro.html"><a href="intro.html#expectation-and-variance"><i class="fa fa-check"></i><b>1.6.3</b> Expectation and variance</a></li>
<li class="chapter" data-level="1.6.4" data-path="intro.html"><a href="intro.html#independence"><i class="fa fa-check"></i><b>1.6.4</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#exchangeability"><i class="fa fa-check"></i><b>1.7</b> Exchangeability</a></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#whats-next"><i class="fa fa-check"></i><b>1.8</b> What’s next</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bin.html"><a href="bin.html"><i class="fa fa-check"></i><b>2</b> The Binomial Model</a>
<ul>
<li class="chapter" data-level="2.1" data-path="bin.html"><a href="bin.html#inference-using-a-uniform-prior"><i class="fa fa-check"></i><b>2.1</b> Inference Using a Uniform Prior</a></li>
<li class="chapter" data-level="2.2" data-path="bin.html"><a href="bin.html#the-beta-distribution"><i class="fa fa-check"></i><b>2.2</b> The Beta Distribution</a></li>
<li class="chapter" data-level="2.3" data-path="bin.html"><a href="bin.html#inference-using-a-beta-prior"><i class="fa fa-check"></i><b>2.3</b> Inference using a Beta Prior</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="bin.html"><a href="bin.html#uniform-as-beta"><i class="fa fa-check"></i><b>2.3.1</b> Uniform as Beta</a></li>
<li class="chapter" data-level="2.3.2" data-path="bin.html"><a href="bin.html#a-generic-beta-prior"><i class="fa fa-check"></i><b>2.3.2</b> A Generic Beta Prior</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="bin.html"><a href="bin.html#predictive-distribution"><i class="fa fa-check"></i><b>2.4</b> Predictive Distribution</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Bayesian Statistics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1" number="1">
<h1><span class="header-section-number">Chapter 1</span> Introduction</h1>
<p>Bayesian statistics is the name given to a whole branch of statistics which differs from the traditional approach taught in introductory statistics classes.</p>
<p>In order to understand what this difference is, let’s first review the basic traditional approach, which is often referred to as <em>frequentist</em> (we will see later on where this word comes from). In general, we are interested about an unknown characteristic of a population, usually called a population <em>parameter</em>. For instance, we may be interested in the mean annual salary of an individual living in the city of Madrid. Let’s call this quantity <span class="math inline">\(\mu\)</span>. Suppose it is impossible to exactly compute this quantity by accessing the information about the salary of everyone living in Madrid.</p>
<p>The next step would be to collect a sample, let’s call it <span class="math inline">\(y\)</span>, with information about the salary of some inhabitants of Madrid. We would then use this sample to come up with a best guess, or an estimate, of <span class="math inline">\(\mu\)</span>. Due to multiple reasons which are not of interest here, we know that computing the sample mean <span class="math inline">\(\bar{y}\)</span> is an optimal way to estimate <span class="math inline">\(\mu\)</span> and we denote such a value <span class="math inline">\(\hat{\mu}\)</span>.</p>
<p>In most cases, having just a single value is not satisfactory enough, and we instead want an interval of values which would likely contain the true value <span class="math inline">\(\mu\)</span>. So a follow-up step would be to construct a so-called <em>confidence interval</em>. You may recall that a confidence interval for a mean can be computed as
<span class="math display">\[
\hat{\mu}\pm z_{\alpha}\sqrt{\frac{\hat{\sigma}^2}{n}},
\]</span>
where</p>
<ul>
<li><p><span class="math inline">\(n\)</span> is the sample size;</p></li>
<li><p><span class="math inline">\(\hat{\sigma}^2\)</span> is an estimate of the population variance, that is a guess of how much variability there is around the mean;</p></li>
<li><p><span class="math inline">\(z_{\alpha}\)</span> is some value that comes either from a Normal or T-Student distribution which depends on how confident we want to be that the true <span class="math inline">\(\mu\)</span> lies within the interval.</p></li>
</ul>
<p>In the so-called frequentist approach we only used the data to guide the estimation of the unknown parameter and we assumed that we had no <em>prior</em> information about what plausible values of <span class="math inline">\(\mu\)</span> might be. Suppose on the other hand that in advance we had some guessing that the true value of <span class="math inline">\(\mu\)</span> may lie within 20k and 50k. In the frequentist approach there is no way to embed this information within the inferential process. Only the data can be used to guide the estimation of the parameters. The <em>Bayesian</em> approach on the other hand is designed to formally account prior information about the unknown parameter in the inferential process.</p>
<div id="a-more-technical-discussion" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> A more technical discussion</h2>
<p>In order to understand how the Bayesian approach actually works, let’s discuss slightly more formally how the frequentist estimation process works. Let’s more generally call <span class="math inline">\(\theta\)</span> the unknown population parameter that we want to estimate and <span class="math inline">\(y\)</span> the sample. Depending on the type of data we are working with, we start choosing a statistical model, or a data-generating process, <span class="math inline">\(p(y|\theta)\)</span>. To make this clearer, consider the following examples:</p>
<ul>
<li><p>suppose that we observe coin tosses and we are interested in the probability of head: then the standard choice for <span class="math inline">\(p(y|\theta)\)</span> would be the probability mass function of a Bernoulli distribution.</p></li>
<li><p>suppose we collect information about the number of goals scored in football matches: then the standard choice for <span class="math inline">\(p(y|\theta)\)</span> would be the probability mass function of a Poisson distribution;</p></li>
<li><p>often we let <span class="math inline">\(p(y|\theta)\)</span> be the probability density function of a Normal distribution. Such a choice is in general due to the <em>Central Limit Theorem</em> which tells us that if our sample size is large enough then any distribution is well approximated by a Normal.</p></li>
</ul>
<p>The quantity <span class="math inline">\(p(y|\theta)\)</span> is also often referred to as the <em>likelihood</em> and written as <span class="math inline">\(L(\theta|y)\)</span>. Notice that the order of <span class="math inline">\(\theta\)</span> and <span class="math inline">\(y\)</span> is reversed: whilst <span class="math inline">\(p(y|\theta)\)</span> is seen as the distribution of <span class="math inline">\(y\)</span> given the parameter <span class="math inline">\(\theta\)</span>, <span class="math inline">\(L(\theta|y)\)</span> is seen as a measure of how likely is that the parameter is <span class="math inline">\(\theta\)</span> given that we observed the sample <span class="math inline">\(y\)</span>.</p>
<p>No matter what the interpretation is, we view as random only the process that generated the data which is assumed to behave according to some distribution <span class="math inline">\(p(y|\theta)\)</span>. The parameter <span class="math inline">\(\theta\)</span> is itself assumed to be fixed and unknown: it is not random, it is just that we do not know its value. We use <span class="math inline">\(p(y|\theta)\)</span> to come up with an estimate <span class="math inline">\(\hat\theta\)</span> of the unknwon <span class="math inline">\(\theta\)</span>. For instance in maximum likelihood estimation <span class="math inline">\(\hat\theta\)</span> is found as
<span class="math display">\[
\hat\theta = \arg\max_{\theta} p(y|\theta)
\]</span></p>
<p>The Bayesian approach differs from the frequentist approach since it consider the unknown parameter <span class="math inline">\(\theta\)</span> to also be a random variable and not simply fixed. Therefore in Bayesian statistics the unknown parameter is also assigned a distribution, <span class="math inline">\(p(\theta)\)</span>, which is referred to as <em>prior</em> distribution. Furthermore, the main building block of Bayesian statistics is a joint distribution for the data-generating process and the unknown parameter, since both are random. Such a distribution is
<span class="math display">\[
p(y,\theta),
\]</span>
which by using basic rules of conditional probabilities can be written as
<span class="math display">\[
p(y,\theta) = p(y|\theta)p(\theta).
\]</span>
The above expression can be seen as the product of the data-generating distribution, or likelihood, with the prior distribution.</p>
<p>The prior distribution encodes our beliefs about the unknown parameter of interest before observing any data. Now suppose we collect the sample <span class="math inline">\(y\)</span>: we would like to use it to revise or update our beliefs about the unknown parameter <span class="math inline">\(\theta\)</span>. This is done using Bayes theorem, hence the name Bayesian statistics. Most likely, you are already familiar with the version of Bayes theorem for events namely:
<span class="math display">\[
P(A|B) = \frac{P(B|A)P(A)}{P(B)}.
\]</span>
Similarly we can write</p>
<p><span class="math display" id="eq:posterior">\[\begin{equation}
 \tag{1.1}
p(\theta|y) = \frac{p(y|\theta)p(\theta)}{p(y)}
\end{equation}\]</span></p>
<p>and <span class="math inline">\(p(\theta|y)\)</span> is usually called the <em>posterior distribution</em>: it encodes our beliefs about <span class="math inline">\(\theta\)</span> after having observed the sample <span class="math inline">\(y\)</span>. Equation <a href="intro.html#eq:posterior">(1.1)</a> is the backbone of Bayesian statistics and the main task in a Bayesian analysis is to compute such a posterior distribution.</p>
<p>There are two important observations to make now. First, in Equation <a href="intro.html#eq:posterior">(1.1)</a> the terms <span class="math inline">\(p(y|\theta)\)</span> and <span class="math inline">\(p(\theta)\)</span> are chosen by the modeler, whilst <span class="math inline">\(p(y)\)</span> can be computed from these two as:
<span class="math display">\[
p(y)=\int p(y,\theta)d\theta=\int p(y|\theta)p(\theta)d\theta
\]</span>
and it is called <em>marginal likelihood</em>. So Equation <a href="intro.html#eq:posterior">(1.1)</a> can also be written as
<span class="math display">\[
p(\theta|y) = \frac{p(y|\theta)p(\theta)}{\int p(y|\theta)p(\theta)d\theta}.
\]</span></p>
<p>Second, our object of study is the parameter <span class="math inline">\(\theta\)</span> and <span class="math inline">\(p(\theta|y)\)</span> is a function of <span class="math inline">\(\theta\)</span> only. So the term <span class="math inline">\(p(y)\)</span> at the denominator of Equation <a href="intro.html#eq:posterior">(1.1)</a> is actually only a normalization constant to make sure that <span class="math inline">\(p(\theta|y)\)</span> integrates to 1. So Equation <a href="intro.html#eq:posterior">(1.1)</a> is often presented as</p>
<p><span class="math display" id="eq:posterior1">\[\begin{equation}
 \tag{1.2}
p(\theta|y)\propto p(y|\theta)p(\theta).
\end{equation}\]</span></p>
<p>Equation <a href="intro.html#eq:posterior1">(1.2)</a> is actually the one that most often we will work with since <span class="math inline">\(p(y)\)</span> is not actually necessary and it is often very hard to compute.</p>
<p>One question you might have is: why did we combine the prior distribution and data-generating distribution using Bayes Theorem? We could have used different rules to come up with a so-called posterior distribution. We will not enter into the details of this, but if beliefs are encoded as probability distributions, then it can proved that Bayes theorem is the optimal way to update them in the light of data.</p>
</div>
<div id="a-first-example" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> A first example</h2>
<p>Suppose we are interested in estimating the prevalence of COVID-19 cases in the city of Madrid. For this purpose we select a sample of 100 individuals living in the city. Let’s assume that each individual has the same probability of having the disease and that each individual has the disease independently of others.</p>
<p>Then we could model the fact that each individual has the disease as a Bernoulli distribution, where the value 1 denotes having the disease. Suppose the result of COVID testing over these 100 individuals shows that 10 of them are positive. Then we would estimate the parameter <span class="math inline">\(\theta\)</span> of the Bernoulli distribution as <span class="math inline">\(\hat\theta=10/100=0.1\)</span>, which would in turn be our estimate for the prevalence of COVID cases in Madrid. Furthermore, we could construct a 95% confidence interval which, if you recall from previous courses, can be computed as
<span class="math display">\[
\hat\theta\pm 1.96 \sqrt{\frac{\hat\theta(1-\hat\theta)}{n}}= 0.1 \pm 1.96 \sqrt{\frac{0.1\cdot 0.9}{100}}= (0.041,0.159).
\]</span></p>
<p>Let’s take a Bayesian approach instead. For the data-generating process it is still of course reasonable to believe that a Bernoulli distribution with unknown parameter <span class="math inline">\(\theta\)</span> is appropriate. Now we also need to define a prior distribution. Suppose that from data related to other European cities, we believe that such a prevalence number is between 0.05 and 0.25 with an average around 0.15. We will later learn ways to choose prior distributions, but suppose that such a prior information can be represented by the distribution colored in blue in Figure <a href="intro.html#fig:example">1.1</a>. This distribution represents our beliefs about the prevalence of COVID in the city of Madrid.</p>
<div class="figure"><span id="fig:example"></span>
<img src="BayesStats_files/figure-html/example-1.png" alt="Prior and posterior distribution for the COVID example." width="672" />
<p class="caption">
Figure 1.1: Prior and posterior distribution for the COVID example.
</p>
</div>
<p>Suppose we collect the same sample as before of 10 positive out of 100 and compute the posterior distribution using Bayes theorem. This is reported in Figure <a href="intro.html#fig:example">1.1</a> by the red distribution. So differently from the frequentist case where we have a single point estimate of <span class="math inline">\(\theta\)</span> or a confidence interval of plausible values, we now have a full distribution for the variable <span class="math inline">\(\theta\)</span> in the light of data and prior beliefs. Given such a distribution we can do multiple things:</p>
<ul>
<li><p>we can come up with a single point estimate for <span class="math inline">\(\theta\)</span>, for instance the mean or the mode of the distribution;</p></li>
<li><p>we can identify a plausible region of values of <span class="math inline">\(\theta\)</span> in the same spirit of a confidence interval.</p></li>
</ul>
<p>It is important to notice that our beliefs about the prevalence of COVID has now changed in the light of data. Our prior distribution was quite spread around values between 0.05 and 0.25, whilst the posterior is a lot more concentrated around 0.1 which is actually the sample proportion of COVID.</p>
</div>
<div id="why-bayesian-statistics" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Why Bayesian statistics</h2>
<p>The previous example showed an example of a simple Bayesian analysis and how it differs from a frequentist one. One might wonder what is the real advantage of taking a Bayesian approach with respect to a frequentist one: we saw that in the end the conclusion from both approaches was pretty much the same.</p>
<p>In general we can notice the below advantages of a Bayesian approach:</p>
<ul>
<li><p>it allows to more flexibly construct complicated models. This is a concept we will see in later chapters when we will discuss hierarchical models;</p></li>
<li><p>it allows to easily embed in inference other type of information which is not only in the form of data: for instance, expert judgment or results from other studies;</p></li>
<li><p>it allows to use data in a sequential manner. Suppose we carried out our analysis about COVID prevalence and once finished we are actually given the result of tests on new individuals. In the Bayesian framework, we could then use our posterior from the previous step as our new prior and use the same machinery to come up with a new posterior. In a frequentist setting, we would need to use the full dataset again to come up with an estimate of <span class="math inline">\(\theta\)</span>. Of course this is trivial in the COVID example, but for much more complicated models, it may be very costly to repeat the analysis with the full dataset.</p></li>
<li><p>it leads to an intuitive interpretation of confidence intervals. Standard confidence intervals are probability statements about <span class="math inline">\(\hat\theta\)</span> and not <span class="math inline">\(\theta\)</span> itself as often erraneosly thought. The correct interpretation of a 95% confidence interval is that if we were to collect many many times samples under the same conditions and each time construct a confidence interval, then 95% of the times the interval would include the true value <span class="math inline">\(\theta\)</span>. However, most often people interpret confidence intervals as with 95% probability the true unknown parameter lies in the interval, which is not correct. However, this is the interpretation of confidence intervals in the Bayesian setup;</p></li>
<li><p>it can deal more easily with rare situations. Let’s consider the COVID example again and suppose that on the other hand we observed zero positive tests. Then our point estimate of the prevalance would be zero and confidence intervals at any level of confidence (even 99.9999%) would simply be the point zero, which we would in general not believe unless the sample size is extremely large! Using the same prior as before, in the case of zero positive cases our posterior would be the one in Figure <a href="intro.html#fig:example1">1.2</a>. Although most of the distribution is around zero, we still have some probability that the prevalence is some small number close to zero. The more and more only negative tests we would collect, the more the distribution would be concentrated in zero!</p></li>
</ul>
<div class="figure"><span id="fig:example1"></span>
<img src="BayesStats_files/figure-html/example1-1.png" alt="Prior and posterior distribution for the COVID example." width="672" />
<p class="caption">
Figure 1.2: Prior and posterior distribution for the COVID example.
</p>
</div>
<p>Of course there are also drawbacks of the Bayesian approach. The main critic regards the prior distribution and the addition of a “subjective” element in the analysis. We will discuss a lot more this issue in the next chapter. The second drawback is that it is computationally much more expensive and most often Bayesian methods require more computational power and computational time. As we will see in the next section, this was actually one of the reasons Bayesian methods were not used for many years.</p>
</div>
<div id="a-bit-of-history" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> A bit of history</h2>
<p>The term Bayesian statistics comes from the fact that inference is based upon a sequential use of Bayes theorem. Reverend Thomas Bayes was an English minister whose 1763 posthumosly paper “An Essay Towards Solving a Problem in the Doctrine of Chances” gives the first account of what we now call Bayes theorem. As a matter of fact, his account of the result is not in the form you are familiar with. It was Pierre Simon Laplace, an 18th century French scientist, who introduced Bayes theorem in a form much more similar to the one we use today in his essay “Memoire sur la Probabilite des Causes par les Evenements.”</p>
<p>Laplace was actually studying the probability of a “success” in a Binomial experiment given that data was observed. In the terminology we introduced he was characterizing the posterior distribution of <span class="math inline">\(\theta\)</span>. The method of deriving a probability distribution for an unknown parameter given data was overall called the “inverse probability” problem and became the gold standard throughout the 19th century.</p>
<p>Of course there were many scientists that critiqued such a method, including Boole and Venn, due to the non-objectivity of the method. However, since no alternative was available at the time, the inverse probability method continued to be the gold-standard.</p>
<p>It was only at the beginning of the 20th century with the work of Ronald Alymer Fisher, Jerzy Neyman and Egon Pearson, that the frequentist approach became to emerge. Therefore, the approach of statistics that is most frequently taught is actually less recent than Bayesian ideas.</p>
<p>Although frequentist approached dominated statistics, Bayesian ideas were still being developed in the first half of the 20th century through the work on subjective probabilities of Harold Jeffreys, Bruno de Finetti and Leonard Savage.</p>
<p>In the second half of the century there was a resurgence of Bayesian methods. Two of the main reasons were:</p>
<ul>
<li><p>the work on expected utility of von Neumann and Morgenstern where a subjective view of probability can be more easily accepted became very popular;</p></li>
<li><p>computational power increased at a speed never seen before and a lot of complex problems could be at last approached with a Bayesian approach.</p></li>
</ul>
<p>Nowadays Bayesian statistics is as popular as frequentist statistics and research is carried out almost equally in the two frameworks. There are indeed problems that can be more easily tackled with a Bayesian approach (and the other way around too, of course!).</p>
</div>
<div id="interpretations-of-probability" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Interpretations of probability</h2>
<p>The field of Bayesian statistics is deeply connected to a different interpretation of probability then the ones you are probably familiar with.</p>
<p>The most common and basic interpretation of probability is due to Pierre Simon Laplace and is based on the notion of symmetry of elementary outcomes or, to put it differently, on the notion of equiprobability. In Laplace’s definition the probability of an event is defined as the number of favourable cases over the number of total cases. Let’s consider the throw of a simple dice and the event that the number shown is even. There are three favourable cases (2,4 and 6) and six total cases (the numbers from 1 to 6). The probability of this event is therefore one half as one would expect. Of course this definition applies only to cases where elementary outcomes are equiprobable: in the example if the dice is not biased.</p>
<p>The second most common interpretation is the so-called <em>frequentist</em> one. Probability is defined as the relative frequency in a long sequence of identical independent trials. It is assumed that there is an underlying generating process which every times generates an independent instance. Let’s consider again the event of an even number in a dice throw. The probability of this event is defined as the frequency of even numbers if we were to repeat the throw of a dice an infinite number of times. Figure <a href="intro.html#fig:dice">1.3</a> illustrates how the relative frequency of even numbers evolves in 500 throws. The red line is the relative frequency: for the first 100 tries it is quite far away from the value 0.5 and then it slowly stabilizes at the true value.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="intro.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2021</span>)</span>
<span id="cb1-2"><a href="intro.html#cb1-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>,<span class="dv">500</span>,<span class="cn">TRUE</span>)<span class="sc">%%</span> <span class="dv">2</span> <span class="sc">==</span> <span class="dv">0</span></span>
<span id="cb1-3"><a href="intro.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">cumsum</span>(x)<span class="sc">/</span><span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>,<span class="at">type=</span><span class="st">&quot;l&quot;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Probability&quot;</span>)</span>
<span id="cb1-4"><a href="intro.html#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fl">0.5</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:dice"></span>
<img src="BayesStats_files/figure-html/dice-1.png" alt="Relative frequency of even numbers in 500 dice throws" width="50%" />
<p class="caption">
Figure 1.3: Relative frequency of even numbers in 500 dice throws
</p>
</div>
<p>Now let’s think at some other types of events:</p>
<ul>
<li><p>Spain winning the next world cup;</p></li>
<li><p>the next expedition to Mars fails;</p></li>
<li><p>it rains tomorrow.</p></li>
</ul>
<p>It becomes challenging to define probability as relative frequency since we cannot think of a sequence of repetitions of such processes that are exactly equal. Such events are in general <em>non-reproducible</em>. However, we can think of defining a probability that these events happen, which in a way encodes our <em>degree of belief</em> that the event will happen. Notice that such a degree of belief is personal and may vary from individual to individual (a Spaniard may give a higher probability of Spain winning a World Cup than a foreigner). For this reason, this interpretation of probability is usually referred to as <em>subjective</em>.</p>
<p>A classical way to define probabilities in the subjective framework is in terms of betting odds. Consider an event <span class="math inline">\(A\)</span>. Then <span class="math inline">\(P(A)\)</span>, the probability of <span class="math inline">\(A\)</span>, is the amount you are willing to pay for a lottery ticket that pays one Euro if <span class="math inline">\(A\)</span> happens. Notice the <em>you</em> in the previous sentence. It is your probability and depends on the information available to <em>you</em>. We will not focus on this, but it has been proved that if one specifies probabilities in this way, and assuming you choose the numbers in order to win money, then subjective probabilities respect the usual axioms probabilities (probabilities are numerical quantities, defined
on a set of ‘outcomes,’ that are non-negative, additive over mutually exclusive outcomes, and sum to 1 over all possible mutually exclusive outcomes).</p>
<p>The following quote from De Finetti is provocative.</p>
<blockquote>
<p>My thesis, paradoxically, and a little provocatively, but nonetheless
genuinely, is simply this:</p>
<p>PROBABILITY DOES NOT EXIST</p>
<p>The abandonment of superstitious beliefs about the existence of Phlogiston, the Cosmic Ether, Absolute Space and Time, . . . , orFairies and Witches, was an essential step along the road to scientific thinking. Probability, too, if regarded as something endowed with some kind of objective existence, is no less a misleading misconception, an illusory attempt to exteriorize or materialize our true probabilistic beliefs.</p>
</blockquote>
<p>This interpretation of probability is the one underlying most Bayesian analyses. In Bayesian statistics unknown quantities (for instance parameters of interest) are random variables and probabilities must be assigned to them by the modeler.</p>
<p>Another approach sees probability as a <em>logic of plausibility</em>. This approach was put forward by statisticians as Jeffreys, Cox and Jaynes. According to this interpretation, the rules of probability extend ordinary (“Boolean”) logic, where statements are known to be either true or false, to inductive logic, where statements are true or false, but we don’t know which. Probability is then a scale used to describe how strongly, based on specific information, we believe a statement to be true. It is a more objective approach in the sense that anyone with the same knowledge should assign the same probabilities. Again we will not focus on this, but then one can prove the probabilities so defined obey the usual axioms.</p>
<p>The following quote from Maxwell gives a justification of this approach.</p>
<blockquote>
<p>They say that Understanding ought to work by the rules of right reason. These rules are, or ought to be, contained in Logic; but the actual science of logic is conversant at present only with things either certain, impossible, or entirely doubtful, none of which (fortunately) we have to reason on. Therefore the true logic for this world is the calculus of Probabilities, which takes account of the magnitude of the probability which is, or ought to be, in a reasonable man’s mind.</p>
</blockquote>
<p>The above discussion is brief and not at all comprehensive but it should have given you at least an idea of possible different interpretations of probability.</p>
</div>
<div id="a-review-of-probability" class="section level2" number="1.6">
<h2><span class="header-section-number">1.6</span> A review of probability</h2>
<div id="random-variables" class="section level3" number="1.6.1">
<h3><span class="header-section-number">1.6.1</span> Random variables</h3>
<p>A random variable is defined as an unknown numerical quantity about which we make probability statements.</p>
<div id="discrete-random-variables" class="section level4" number="1.6.1.1">
<h4><span class="header-section-number">1.6.1.1</span> Discrete random variables</h4>
<p>Let <span class="math inline">\(Y\)</span> be a random variable and <span class="math inline">\(\mathbb{Y}\)</span> be the set of all possible values of <span class="math inline">\(Y\)</span>. Usually, <span class="math inline">\(\mathbb{Y}\)</span> is called the <em>sample space</em>. We say that <span class="math inline">\(Y\)</span> is discrete if <span class="math inline">\(\mathbb{Y}\)</span> is countable, meaning that <span class="math inline">\(\mathbb{Y}\)</span> can be expressed as <span class="math inline">\(\mathbb{Y} = \{y_1, y_2,\dots\}\)</span>.</p>
<p>For each <span class="math inline">\(y\in\mathbb{Y}\)</span>, we define the <em>probability density function</em> (pdf) <span class="math inline">\(p(y)=P(Y=y)\)</span> which must obey the following conditions:</p>
<ul>
<li><p><span class="math inline">\(p(y)\geq 0\)</span> for all <span class="math inline">\(y\in\mathbb{Y}\)</span>;</p></li>
<li><p><span class="math inline">\(\sum_{y\in\mathbb{Y}}p(y)=1\)</span>.</p></li>
</ul>
<p>For any <span class="math inline">\(A\subseteq \mathbb{Y}\)</span>, the probability that <span class="math inline">\(Y\in A\)</span> can be computed via summation as
<span class="math display">\[
P(Y\in A) = \sum_{y\in A} p(y).
\]</span></p>
</div>
<div id="continuous-random-variables" class="section level4" number="1.6.1.2">
<h4><span class="header-section-number">1.6.1.2</span> Continuous random variables</h4>
<p>If the sample space <span class="math inline">\(\mathbb{Y}\)</span> is an interval, not necessarily finite (for instance it could be the set of all real numbers <span class="math inline">\(\mathbb{R}\)</span>), we say that <span class="math inline">\(Y\)</span> is a continuous random variable.</p>
<p>The pdf of a continuous random variable <span class="math inline">\(Y\)</span> is now defined as the function <span class="math inline">\(p\)</span> for which:
<span class="math display">\[
P(a\leq Y \leq b) = \int_a^b p(y)dy
\]</span></p>
<p>We cannot define <span class="math inline">\(P(a \leq Y \leq b)\)</span> as equal to <span class="math inline">\(\sum_{a\leq y \leq b}p(y)\)</span> because the sum does not make sense (the set of real numbers between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> is “uncountable”). So pdfs are defined indirectly as the function such that its integral is the probability of the corresponding event.</p>
<p>The pdf of a continuous random variable must again obey two conditions:</p>
<ul>
<li><p><span class="math inline">\(p(y)\geq 0\)</span>, for all <span class="math inline">\(y\in\mathbb{Y}\)</span>;</p></li>
<li><p><span class="math inline">\(\int_{y\in\mathbb{R}}p(y)dy =1\)</span>.</p></li>
</ul>
<p>We can see that integration for continuous distributions behaves similarly to summation for discrete distributions. In fact, integration can be thought of as a generalization of summation for situations in which the sample space is not countable. However, unlike a pdf in the discrete case, the pdf for a continuous
random variable is:</p>
<ul>
<li><p>Not necessarily less than 1;</p></li>
<li><p><span class="math inline">\(p(y)\)</span> is not “the probability that <span class="math inline">\(Y = y\)</span>”;</p></li>
<li><p>such that <span class="math inline">\(P(Y=y)=0\)</span> for any <span class="math inline">\(y\in\mathbb{Y}\)</span>.</p></li>
</ul>
<p>However, if <span class="math inline">\(p(y_1) &gt; p(y_2)\)</span> we will sometimes informally say that <span class="math inline">\(y_1\)</span> “has a higher probability” than <span class="math inline">\(y_2\)</span>.</p>
</div>
</div>
<div id="joint-distributions" class="section level3" number="1.6.2">
<h3><span class="header-section-number">1.6.2</span> Joint distributions</h3>
<div id="discrete-case" class="section level4" number="1.6.2.1">
<h4><span class="header-section-number">1.6.2.1</span> Discrete case</h4>
<p>Let <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> be two discrete random variables with <span class="math inline">\(\mathbb{Y}_1\)</span> and <span class="math inline">\(\mathbb{Y}_2\)</span> as sample spaces, respectively. We are often interested in joint beliefs about two variables. For instance we may want to know
<span class="math display">\[
P(Y_1=y_1,Y_2=y_2), \hspace{1cm} \mbox{for } y_1\in\mathbb{Y}_1 \mbox{ and } y_2\in \mathbb{Y}_2
\]</span></p>
<p>The (joint) pdf is then <span class="math inline">\(p(y_1,y_2)=P(Y_1=y_1,Y_2=y_2)\)</span>.</p>
<p>The <em>marginal density</em> of <span class="math inline">\(Y_1\)</span> can be computed from the joint as:
<span class="math display">\[
p(y_1)=P(Y_1=y_1)=\sum_{y_2\in\mathbb{Y}_2}P(Y_1=y_1,Y_2=y_2)=\sum_{y_2\in\mathbb{Y}_2}p(y_1,y_2)
\]</span></p>
<p>The <em>conditional density</em> of <span class="math inline">\(Y_2\)</span> given <span class="math inline">\(Y_1=y_1\)</span> can be computed from the joint and the marginal as:
<span class="math display">\[
p(y_2|Y_1=y_1)=\frac{p(y_1,y_2)}{p(y_1)}
\]</span>
Re-arranging the above equation we can also see that
<span class="math display">\[
p(y_1,y_2)= p(y_2|Y_1=y_1)p(y_1)
\]</span></p>
<p>Let’s consider an example. Suppose we have a random variable <span class="math inline">\(Y_1\)</span> which is the outcome of a COVID-19 test (either positive or negative) and <span class="math inline">\(Y_2\)</span> which is whether an individual has COVID or not (sick or healthy). The joint probability distribution is defined as</p>
<p><span class="math display">\[
\begin{matrix}
    \begin{array}{c|cc} \hline
    &amp;\text{sick} &amp; \text{healthy} \\\hline
    \text{positive} &amp; 0.10 &amp; 0.09 \\\hline
    \text{negative} &amp; 0.01 &amp; 0.80 \\\hline
    \end{array}
\end{matrix}
\]</span></p>
<p>The above table is a joint pdf since all numbers are positive and sum to one. The marginal probability of <span class="math inline">\(Y_1\)</span> (test result) is the row sums: 19% of tests are positive and 81% of tests are negative. The marginal probability of <span class="math inline">\(Y_2\)</span> is the column sums: 11% of individuals are sick and 89% are healthy. Given these marginals we can also compute conditional probabilities:</p>
<ul>
<li><p><span class="math inline">\(p(\text{positive}|\text{sick})= \frac{p(\text{positive},\text{sick})}{p(\text{sick})}=\frac{0.10}{0.11}=0.91\)</span></p></li>
<li><p>therefore <span class="math inline">\(p(\text{negative}|\text{sick})=0.09\)</span>.</p></li>
</ul>
<p>Other conditional probabilities can be derived similarly.</p>
</div>
<div id="continuous-case" class="section level4" number="1.6.2.2">
<h4><span class="header-section-number">1.6.2.2</span> Continuous case</h4>
<p>In the continuous case the definitions are analogous but summations are substituted with integrals. For instance,
<span class="math display">\[
p(y_1)= \int_{y_2\in\mathbb{Y}_2}p(y_1,y_2)dy_2
\]</span></p>
</div>
</div>
<div id="expectation-and-variance" class="section level3" number="1.6.3">
<h3><span class="header-section-number">1.6.3</span> Expectation and variance</h3>
<p>The mean or expectation of a random variable <span class="math inline">\(Y\)</span> is</p>
<ul>
<li><p><span class="math inline">\(E(Y)=\sum_{y\in\mathbb{Y}} y p(y)\)</span> in the discrete case;</p></li>
<li><p><span class="math inline">\(E(Y)=\int_{y\in\mathbb{Y}}yp(y)dy\)</span> in the continuous case.</p></li>
</ul>
<p>The mean is the center of mass of the distribution.</p>
<p>In addition to the location of a distribution we are often interested in how
spread out it is. The most popular measure of spread is the variance of a
distribution:
<span class="math display">\[
V(Y)=E((Y-E(Y))^2)= E(Y^2) - E(Y)^2
\]</span>
The variance is the average squared distance between values of <span class="math inline">\(Y\)</span> and its mean <span class="math inline">\(E(Y)\)</span>. The standard deviation is the square root of the variance, and is on the same scale as <span class="math inline">\(Y\)</span>.</p>
<p>Above we have defined conditional densities of the form <span class="math inline">\(p(y_2|Y_1=y_1)\)</span>. Since formally they are pdfs they have expectation and variance which are usually denoted as <span class="math inline">\(E(Y_2|Y_1=y_1)\)</span> and <span class="math inline">\(V(Y_2|Y_1=y_1)\)</span>.</p>
<p>Furthermore, it is often useful to express the mean and variance of a random variable <span class="math inline">\(Y_2\)</span> in terms of the conditional mean and variance given some related quantity <span class="math inline">\(Y_1\)</span>. The mean of <span class="math inline">\(Y_2\)</span> can be obtained by averaging the conditional mean over the marginal distribution of <span class="math inline">\(Y_1\)</span>:
<span class="math display">\[
E(Y_2)=E(E(Y_2|Y_1=y_1)).
\]</span>
Let’s see why this is true:
<span class="math display">\[\begin{eqnarray*}
E(Y_2) &amp;=&amp;\sum_{y_2\in\mathbb{Y}_2}y_2p(y_2)\\
 &amp;=&amp;\sum_{y_2\in\mathbb{Y}_2}y_2\sum_{y_1\in\mathbb{Y}_1}p(y_1,y_2)\\
 &amp;=&amp;\sum_{y_2\in\mathbb{Y}_2}\sum_{y_1\in\mathbb{Y}_1}y_2p(y_2|Y_1=y_1)p(y_1)\\
 &amp;=&amp;\sum_{y_1\in\mathbb{Y}_1}p(y_1)\sum_{y_2\in\mathbb{Y}_2}y_2p(y_2|Y_1=y_1)\\
 &amp;=&amp;\sum_{y_1\in\mathbb{Y}_1}p(y_1)E(Y_2|Y_1=y_1)\\
 &amp;=&amp; E(E(Y_2|Y_1=y_1))
\end{eqnarray*}\]</span></p>
<p>The corresponding result for the variance includes two terms, the mean of the conditional
variance and the variance of the conditional mean:
<span class="math display">\[
V(Y_2) = E(V(Y_2|Y_1=y_1)) + V(E(Y_2|Y_1=y_1))
\]</span></p>
</div>
<div id="independence" class="section level3" number="1.6.4">
<h3><span class="header-section-number">1.6.4</span> Independence</h3>
<p>We say that two random variables are independent if
<span class="math display">\[
p(y_1,y_2) = p(y_1)p(y_2)
\]</span>
that is if the joint distribution can be written as the product of the marginal distributions.</p>
<p>In Bayesian statistics we usually make the assumption that we have independent random variables <span class="math inline">\(Y_1,Y_2,\dots,Y_N\)</span> which all depend on a parameter <span class="math inline">\(\theta\)</span>, which is also believed to be random variable. We say that <span class="math inline">\(Y_1,\dots,Y_N\)</span> are conditionally independent given <span class="math inline">\(\theta\)</span> if
<span class="math display">\[
p(y_1,\dots,y_N|\theta)=\prod_{i=1}^Np(y_i|\theta).
\]</span>
Another way to say this is that <span class="math inline">\(Y_1,\dots,Y_N\)</span> are conditionally independent and identically distributed (iid).</p>
<p>Notice that in standard statistical practice when we analyze a sample we start with the assumption that the data are realizations of independent and identically distributed random variables (not conditionally, since the parameter is not considered random).</p>
</div>
</div>
<div id="exchangeability" class="section level2" number="1.7">
<h2><span class="header-section-number">1.7</span> Exchangeability</h2>
<p>In many situations with several random variables, we would believe that the specific order of observation of these random variables is not important. For example, consider a random sample of 3 participants from an infinite population which may or may not have a property (1 or 0) It makes sense that
<span class="math display">\[
p(1,0,0) = p(0,1,0) = p(0,0,1).
\]</span>
Such a property is called <em>exchangeability</em>.</p>
<p>Let <span class="math inline">\(Y_1,\dots,Y_N\)</span> be random variables. If <span class="math inline">\(p(y_1,\dots,y_N)=p(y_{\pi_1},\dots,y_{\pi_N})\)</span> for all permutations <span class="math inline">\(\pi\)</span> of <span class="math inline">\(\{1,\dots,N\}\)</span>, then <span class="math inline">\(Y_1,\dots,Y_N\)</span> are exchangeable.</p>
<p>Roughly speaking, <span class="math inline">\(Y_1,\dots, Y_n\)</span> are exchangeable if the subscript labels convey no information about the outcomes.</p>
<p>The following result (often called De Finetti’s Theorem) tells us that it is sufficient to assume exchangeability for random variables to be (conditionally) iid.</p>
<p><span class="math display">\[
Y_1,\dots,Y_N \mbox{ are iid } \Longleftrightarrow Y_1,\dots,Y_n \mbox{ are exchangeable for all N&#39;s}
\]</span></p>
<p>So notice that in Bayesian statistics we are actually starting from a weaker assumption about the data-generating process.</p>
</div>
<div id="whats-next" class="section level2" number="1.8">
<h2><span class="header-section-number">1.8</span> What’s next</h2>
<p>This introduction should have given you a feeling of what a Bayesian analysis entails and the various steps required. In the next chapters we will dig deeper into the various components of a Bayesian analysis, namely:</p>
<ul>
<li><p>we will learn how to compute posterior distributions for a variety of simple models;</p></li>
<li><p>we will discuss how to summarize a posterior distribution to come up with point estimates and confidence intervals;</p></li>
<li><p>we will investigate various types of prior distributions and their effect to the posterior distribution;</p></li>
<li><p>we will learn how to construct more complex models within a Bayesian framework, which are usually called hierarchical or multilevel models.</p></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bin.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["BayesStats.pdf", "BayesStats.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
